# üß† MLP from Scratch: AdamW + Cosine Scheduler

–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ **—Å –Ω—É–ª—è –Ω–∞ NumPy** –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–æ–≥–æ, —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø–æ–¥ –∫–∞–ø–æ—Ç–æ–º PyTorch.

**–¶–µ–ª—å –ø—Ä–æ–µ–∫—Ç–∞ (–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è):** –ø–æ–Ω—è—Ç—å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é, —á–∏—Å–ª–µ–Ω–Ω—É—é —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å, backprop –∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ ‚Äî –±–µ–∑ —É—Å–ª–æ–∂–Ω–µ–Ω–∏–π end-to-end CV.

**–ó–∞–¥–∞—á–∞:** –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è CIFAR-10 –Ω–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞—Ö –∏–∑ –∑–∞–º–æ—Ä–æ–∂–µ–Ω–Ω–æ–≥–æ ViT.

```
Frozen ViT ‚Üí Embeddings ‚Üí MLP (–Ω–∞—à–∞ NumPy-—Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è) ‚Üí 10 –∫–ª–∞—Å—Å–æ–≤
```

---

## üéØ –ß—Ç–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –≤—Ä—É—á–Ω—É—é (NumPy)

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|----------|
| `Linear` | –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π —Å He-–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π |
| `ReLU`, `GELU` | –§—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ |
| `Dropout` | –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è |
| `CrossEntropyLoss` | Softmax + NLL (numerically stable) |
| `AdamW` | Adam —Å decoupled weight decay |
| `CosineScheduler` | Cosine annealing —Å warmup |
| `Backpropagation` | Chain rule —á–µ—Ä–µ–∑ –≤—Å–µ —Å–ª–æ–∏ |

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ (–∞–∫—Ç—É–∞–ª—å–Ω–∞—è)

```
mlp_from_scratch/
‚îú‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ run_exp_1.py           # NumPy —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è (from scratch)
‚îú‚îÄ‚îÄ run_exp_2.py           # PyTorch baseline
‚îú‚îÄ‚îÄ grad_check.py          # –ß–∏—Å–ª–µ–Ω–Ω—ã–π –≥—Ä–∞–¥–∏–µ–Ω—Ç-—á–µ–∫ (finite differences)
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ embeddings.py      # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ ViT + –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
‚îÇ
‚îú‚îÄ‚îÄ numpy_impl/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ layers.py          # Linear, Dropout, base Layer
‚îÇ   ‚îú‚îÄ‚îÄ activations.py     # ReLU, GELU, Softmax
‚îÇ   ‚îú‚îÄ‚îÄ losses.py          # CrossEntropyLoss (+ compute_accuracy)
‚îÇ   ‚îú‚îÄ‚îÄ model.py           # MLP, Sequential
‚îÇ   ‚îú‚îÄ‚îÄ optimizers.py      # SGD, AdamW
‚îÇ   ‚îî‚îÄ‚îÄ schedulers.py      # CosineScheduler, StepScheduler
‚îÇ
‚îî‚îÄ‚îÄ torch_impl/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ model.py           # TorchMLP
    ‚îî‚îÄ‚îÄ trainer.py         # Training loop (+ create_dataloaders)
```

---

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

```bash
pip install -r requirements.txt
wandb login

python run_exp_1.py
python run_exp_2.py
```

---

## üß™ –ì—Ä–∞–¥–∏–µ–Ω—Ç-—á–µ–∫ (–≤–∞–∂–Ω–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è)

–ß–∏—Å–ª–µ–Ω–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç backprop —á–µ—Ä–µ–∑ `MLP + CrossEntropyLoss`:

```bash
python grad_check.py
```

---

## üß™ Smoke test (forward/backward)

```bash
python - <<'PY'
from numpy_impl import MLP, CrossEntropyLoss
import numpy as np

np.random.seed(0)

model = MLP(input_dim=10, hidden_dims=[32], output_dim=3)
criterion = CrossEntropyLoss()

X = np.random.randn(4, 10)
y = np.array([0, 1, 2, 1])

logits = model.forward(X)
loss = criterion(logits, y)
print(f"Loss: {loss:.4f}")
print("‚úÖ Forward OK")

dout = criterion.backward()
model.backward(dout)
print("‚úÖ Backward OK")
PY
```

---

## ‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

–°–º–æ—Ç—Ä–∏ `config.py`. –í–∞–∂–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è warmup –º–µ–∂–¥—É NumPy –∏ PyTorch:

- `warmup_start_factor`: —Å—Ç–∞—Ä—Ç–æ–≤—ã–π –º–Ω–æ–∂–∏—Ç–µ–ª—å learning rate –Ω–∞ warmup (–Ω–∞–ø—Ä–∏–º–µ—Ä `0.01` –∑–Ω–∞—á–∏—Ç ‚Äú–Ω–∞—á–∏–Ω–∞–µ–º —Å 1% –æ—Ç lr‚Äù).

---
```

---

### config.py
```py
from dataclasses import dataclass, field
from typing import List


@dataclass
class Config:
    # Data
    data_dir: str = "./data"
    embedding_model: str = "vit_small_patch16_224"
    num_classes: int = 10

    # Model
    hidden_dims: List[int] = field(default_factory=lambda: [512, 256])
    dropout: float = 0.0

    # Training
    epochs: int = 30
    batch_size: int = 128
    lr: float = 3e-4
    weight_decay: float = 0.05

    # LR schedule
    warmup_epochs: int = 3
    warmup_start_factor: float = 0.01  # start lr = lr * warmup_start_factor
    lr_min: float = 1e-6

    # Adam
    beta1: float = 0.9
    beta2: float = 0.999
    eps: float = 1e-8

    # Wandb
    project: str = "mlp-from-scratch"

    # Misc
    seed: int = 42


def get_config(**kwargs) -> Config:
    """Create config with optional overrides."""
    return Config(**kwargs)
```

---

### numpy_impl/schedulers.py
```py
import numpy as np
from .optimizers import Optimizer


class Scheduler:
    """Base class for learning rate schedulers."""

    def __init__(self, optimizer: Optimizer):
        self.optimizer = optimizer
        self.base_lr = optimizer.lr
        # Make steps 0-based like many schedulers:
        # first call to step() sets current_step = 0
        self.current_step = -1

    def step(self):
        raise NotImplementedError

    def get_lr(self) -> float:
        return self.optimizer.lr


class CosineScheduler(Scheduler):
    """
    Cosine Annealing Learning Rate Scheduler with optional warmup.

    Warmup is linear in *factor space*:
        lr = lr_max * (start_factor + (1 - start_factor) * progress)

    where progress goes from 0 to 1 during warmup.

    After warmup:
        lr = lr_min + 0.5 * (lr_max - lr_min) * (1 + cos(pi * progress))
    """

    def __init__(
        self,
        optimizer: Optimizer,
        total_steps: int,
        warmup_steps: int = 0,
        lr_min: float = 0.0,
        warmup_start_factor: float = 0.0,
    ):
        super().__init__(optimizer)

        if total_steps <= 0:
            raise ValueError(f"total_steps must be > 0, got {total_steps}")

        if warmup_steps < 0:
            raise ValueError(f"warmup_steps must be >= 0, got {warmup_steps}")

        if not (0.0 <= warmup_start_factor <= 1.0):
            raise ValueError(
                f"warmup_start_factor must be in [0, 1], got {warmup_start_factor}"
            )

        self.total_steps = int(total_steps)
        self.warmup_steps = int(warmup_steps)
        self.lr_min = float(lr_min)
        self.warmup_start_factor = float(warmup_start_factor)

        self.lr_max = optimizer.lr

    def step(self) -> float:
        """
        Update learning rate and return current value.
        This scheduler is step-based (call once per optimizer step).
        """
        self.current_step += 1
        s = self.current_step  # 0-based step index

        # If someone calls step() beyond total_steps, clamp to final lr
        if s >= self.total_steps:
            self.optimizer.set_lr(self.lr_min)
            return self.lr_min

        # --------------------
        # Warmup
        # --------------------
        if self.warmup_steps > 0 and s < self.warmup_steps:
            if self.warmup_steps == 1:
                progress = 1.0
            else:
                # s = 0 ... warmup_steps-1 => progress 0 ... 1
                progress = s / (self.warmup_steps - 1)

            factor = self.warmup_start_factor + (1.0 - self.warmup_start_factor) * progress
            lr = self.lr_max * factor
            self.optimizer.set_lr(lr)
            return lr

        # --------------------
        # Cosine
        # --------------------
        cosine_steps = self.total_steps - self.warmup_steps
        t = s - self.warmup_steps  # 0-based index in cosine segment

        if cosine_steps <= 1:
            lr = self.lr_min
        else:
            # t = 0 ... cosine_steps-1 => progress 0 ... 1
            progress = t / (cosine_steps - 1)
            lr = self.lr_min + 0.5 * (self.lr_max - self.lr_min) * (1 + np.cos(np.pi * progress))

        self.optimizer.set_lr(lr)
        return lr

    def state_dict(self) -> dict:
        return {"current_step": self.current_step}

    def load_state_dict(self, state: dict):
        self.current_step = state["current_step"]


class StepScheduler(Scheduler):
    """Step decay: multiply lr by gamma every step_size steps."""

    def __init__(self, optimizer: Optimizer, step_size: int, gamma: float = 0.1):
        super().__init__(optimizer)
        self.step_size = int(step_size)
        self.gamma = float(gamma)

    def step(self) -> float:
        self.current_step += 1
        s = self.current_step

        n_decays = (s + 1) // self.step_size  # decay after step_size updates
        lr = self.base_lr * (self.gamma ** n_decays)

        self.optimizer.set_lr(lr)
        return lr
